{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"./models/train_classifier.py\").read())\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 21] The device is not ready: 'D:\\\\nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-30cb5300fffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/DisasterResponse.db\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(database_filepath)\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(txt)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'file:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[1;31m# Is the path item a zipfile?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.zip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y, category_names = load_data(\"./data/DisasterResponse.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.222, total= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.223, total= 4.1min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.234, total= 4.7min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.214, total= 4.9min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.227, total= 4.6min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.209, total= 2.4min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.202, total= 2.6min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.215, total= 2.9min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.205, total= 2.2min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.212, total= 2.2min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.203, total= 1.7min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.196, total= 1.8min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.205, total= 1.8min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.196, total= 1.8min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.208, total= 1.6min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.225, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.222, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.239, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.215, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.234, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.211, total= 1.7min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.209, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.217, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.206, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.213, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.200, total= 1.4min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.197, total= 1.3min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.210, total= 1.3min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.196, total= 1.4min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.207, total= 1.4min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.227, total= 2.7min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.230, total= 2.7min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.235, total= 2.6min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.218, total= 2.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.232, total= 3.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.215, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.213, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.223, total= 1.8min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.208, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.223, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.214, total= 1.1min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.198, total= 1.2min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.217, total= 1.2min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.202, total= 1.1min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.211, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 101.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf_vec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        st...\n",
       "                                                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                                                               n_estimators=100,\n",
       "                                                                                               n_jobs=None,\n",
       "                                                                                               oob_score=False,\n",
       "                                                                                               random_state=None,\n",
       "                                                                                               verbose=0,\n",
       "                                                                                               warm_start=False),\n",
       "                                                              n_jobs=-1))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__max_features': [5, 10, 50],\n",
       "                         'clf__estimator__min_samples_split': [2, 15, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res.columns = category_names\n",
    "#res2 = pd.melt(res, ignore_index=False)\n",
    "#res2 = res2[res2['value'] == 1]\n",
    "#res2 = res2.reset_index(drop = False).sort_values(by = 'index',axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1\n",
      "step2\n",
      "step3\n",
      "step4\n",
      "\n",
      "Best Parameters: {'clf__estimator__max_features': 50, 'clf__estimator__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "ps,rs,fs,ss  = evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93403376 0.5410628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.97748641 0.2786746  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.9552662  0.36787503 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[171985  16478     33      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "print(ps)\n",
    "print(rs)\n",
    "print(fs)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = MultiLabelBinarizer().fit(Y_test)\n",
    "\n",
    "ps,rs,fs,ss  = precision_recall_fscore_support(np.array(Y_test).reshape(-1), np.array(res).reshape(-1), labels = range(0,36), average= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for label related:\n",
      "[[1048  199    1]\n",
      " [  20 3935    0]\n",
      " [   1    8   24]]\n",
      "Confusion matrix for label request:\n",
      "[[4322    8]\n",
      " [ 128  778]]\n",
      "Confusion matrix for label offer:\n",
      "[[5218    0]\n",
      " [   3   15]]\n",
      "Confusion matrix for label aid_related:\n",
      "[[3032   63]\n",
      " [ 195 1946]]\n",
      "Confusion matrix for label medical_help:\n",
      "[[4817    0]\n",
      " [  93  326]]\n",
      "Confusion matrix for label medical_products:\n",
      "[[4971    0]\n",
      " [  54  211]]\n",
      "Confusion matrix for label search_and_rescue:\n",
      "[[5081    0]\n",
      " [  26  129]]\n",
      "Confusion matrix for label security:\n",
      "[[5142    0]\n",
      " [  19   75]]\n",
      "Confusion matrix for label military:\n",
      "[[5065    0]\n",
      " [  31  140]]\n",
      "Confusion matrix for label child_alone:\n",
      "[[5236]]\n",
      "Confusion matrix for label water:\n",
      "[[4900    0]\n",
      " [  61  275]]\n",
      "Confusion matrix for label food:\n",
      "[[4652    5]\n",
      " [  91  488]]\n",
      "Confusion matrix for label shelter:\n",
      "[[4770    1]\n",
      " [  91  374]]\n",
      "Confusion matrix for label clothing:\n",
      "[[5157    0]\n",
      " [  15   64]]\n",
      "Confusion matrix for label money:\n",
      "[[5107    0]\n",
      " [  28  101]]\n",
      "Confusion matrix for label missing_people:\n",
      "[[5176    0]\n",
      " [  11   49]]\n",
      "Confusion matrix for label refugees:\n",
      "[[5083    0]\n",
      " [  39  114]]\n",
      "Confusion matrix for label death:\n",
      "[[5011    0]\n",
      " [  33  192]]\n",
      "Confusion matrix for label other_aid:\n",
      "[[4553    0]\n",
      " [ 160  523]]\n",
      "Confusion matrix for label infrastructure_related:\n",
      "[[4904    0]\n",
      " [  69  263]]\n",
      "Confusion matrix for label transport:\n",
      "[[4994    0]\n",
      " [  46  196]]\n",
      "Confusion matrix for label buildings:\n",
      "[[4976    0]\n",
      " [  62  198]]\n",
      "Confusion matrix for label electricity:\n",
      "[[5125    0]\n",
      " [  25   86]]\n",
      "Confusion matrix for label tools:\n",
      "[[5202    0]\n",
      " [   8   26]]\n",
      "Confusion matrix for label hospitals:\n",
      "[[5187    0]\n",
      " [   8   41]]\n",
      "Confusion matrix for label shops:\n",
      "[[5208    0]\n",
      " [   6   22]]\n",
      "Confusion matrix for label aid_centers:\n",
      "[[5187    0]\n",
      " [   3   46]]\n",
      "Confusion matrix for label other_infrastructure:\n",
      "[[4999    0]\n",
      " [  59  178]]\n",
      "Confusion matrix for label weather_related:\n",
      "[[3767   22]\n",
      " [ 173 1274]]\n",
      "Confusion matrix for label floods:\n",
      "[[4795    0]\n",
      " [  79  362]]\n",
      "Confusion matrix for label storm:\n",
      "[[4763    2]\n",
      " [  78  393]]\n",
      "Confusion matrix for label fire:\n",
      "[[5181    0]\n",
      " [  12   43]]\n",
      "Confusion matrix for label earthquake:\n",
      "[[4752    7]\n",
      " [  74  403]]\n",
      "Confusion matrix for label cold:\n",
      "[[5129    0]\n",
      " [  25   82]]\n",
      "Confusion matrix for label other_weather:\n",
      "[[4966    2]\n",
      " [  66  202]]\n",
      "Confusion matrix for label direct_report:\n",
      "[[4185   14]\n",
      " [ 140  897]]\n",
      "\n",
      "Best Parameters: {'clf__estimator__max_features': 50, 'clf__estimator__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "ps, rs, fs = evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_(cm):\n",
    "    \n",
    "    return(np.diag(cm)[np.diag(cm).shape[0] -1] / np.sum(cm, axis = 0)[ np.sum(cm, axis = 0).shape[0]-1])\n",
    "\n",
    "def recall_(cm):\n",
    "    \n",
    "    return(np.diag(cm)[np.diag(cm).shape[0] -1] / np.sum(cm, axis = 1)[ np.sum(cm, axis = 1).shape[0]-1])\n",
    "\n",
    "def f1score_(cm):\n",
    "    \n",
    "    return(2 * (precision_(cm) * recall_(cm)) / (precision_(cm)  + recall_(cm)))\n",
    "\n",
    "#https://stats.stackexchange.com/questions/21551/how-to-compute-precision-recall-for-multiclass-multilabel-classification\n",
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    '''\n",
    "    INPUT:\n",
    "    cv model, X_test, Y_test, list of category names\n",
    "    \n",
    "    OUTPUT:\n",
    "    precision, f1 score, recall for each category\n",
    "    '''\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = np.array(Y_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    labels = category_names\n",
    "\n",
    "    conf_mat_dict={}\n",
    "    for label_col in range(len(labels)):\n",
    "        y_true_label = y_true[:, label_col]\n",
    "        y_pred_label = y_pred[:, label_col]\n",
    "        cm = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "        \n",
    "        conf_mat_dict[labels[label_col]] = {}\n",
    "        conf_mat_dict[labels[label_col]] ['conf_mat'] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "        conf_mat_dict[labels[label_col]]['recall']  =  recall_(cm)\n",
    "        conf_mat_dict[labels[label_col]]['precision']  = precision_(cm)\n",
    "        conf_mat_dict[labels[label_col]]['f1_score']  = f1score_(cm)\n",
    "\n",
    "\n",
    "\n",
    "    for label, matrix in conf_mat_dict.items():\n",
    "        print(\"Accuracy metrics for label {}:\".format(label))\n",
    "        print(matrix['conf_mat'])\n",
    "        print(matrix['recall'])\n",
    "        print(matrix['precision'])\n",
    "        print(matrix['f1_score'])\n",
    "\n",
    "    print(\"\\nBest Parameters:\", model.best_params_)\n",
    "\n",
    "    \n",
    "    return(conf_mat_dict)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy metrics for label related:\n",
      "[[1048  199    1]\n",
      " [  20 3935    0]\n",
      " [   1    8   24]]\n",
      "0.7272727272727273\n",
      "0.96\n",
      "0.8275862068965517\n",
      "Accuracy metrics for label request:\n",
      "[[4322    8]\n",
      " [ 128  778]]\n",
      "0.8587196467991169\n",
      "0.989821882951654\n",
      "0.9196217494089836\n",
      "Accuracy metrics for label offer:\n",
      "[[5218    0]\n",
      " [   3   15]]\n",
      "0.8333333333333334\n",
      "1.0\n",
      "0.9090909090909091\n",
      "Accuracy metrics for label aid_related:\n",
      "[[3032   63]\n",
      " [ 195 1946]]\n",
      "0.9089210649229332\n",
      "0.9686411149825784\n",
      "0.9378313253012049\n",
      "Accuracy metrics for label medical_help:\n",
      "[[4817    0]\n",
      " [  93  326]]\n",
      "0.7780429594272077\n",
      "1.0\n",
      "0.8751677852348995\n",
      "Accuracy metrics for label medical_products:\n",
      "[[4971    0]\n",
      " [  54  211]]\n",
      "0.7962264150943397\n",
      "1.0\n",
      "0.8865546218487396\n",
      "Accuracy metrics for label search_and_rescue:\n",
      "[[5081    0]\n",
      " [  26  129]]\n",
      "0.832258064516129\n",
      "1.0\n",
      "0.9084507042253521\n",
      "Accuracy metrics for label security:\n",
      "[[5142    0]\n",
      " [  19   75]]\n",
      "0.7978723404255319\n",
      "1.0\n",
      "0.8875739644970414\n",
      "Accuracy metrics for label military:\n",
      "[[5065    0]\n",
      " [  31  140]]\n",
      "0.8187134502923976\n",
      "1.0\n",
      "0.9003215434083601\n",
      "Accuracy metrics for label child_alone:\n",
      "[[5236]]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Accuracy metrics for label water:\n",
      "[[4900    0]\n",
      " [  61  275]]\n",
      "0.8184523809523809\n",
      "1.0\n",
      "0.9001636661211129\n",
      "Accuracy metrics for label food:\n",
      "[[4652    5]\n",
      " [  91  488]]\n",
      "0.842832469775475\n",
      "0.9898580121703854\n",
      "0.9104477611940298\n",
      "Accuracy metrics for label shelter:\n",
      "[[4770    1]\n",
      " [  91  374]]\n",
      "0.8043010752688172\n",
      "0.9973333333333333\n",
      "0.8904761904761905\n",
      "Accuracy metrics for label clothing:\n",
      "[[5157    0]\n",
      " [  15   64]]\n",
      "0.810126582278481\n",
      "1.0\n",
      "0.8951048951048951\n",
      "Accuracy metrics for label money:\n",
      "[[5107    0]\n",
      " [  28  101]]\n",
      "0.7829457364341085\n",
      "1.0\n",
      "0.8782608695652173\n",
      "Accuracy metrics for label missing_people:\n",
      "[[5176    0]\n",
      " [  11   49]]\n",
      "0.8166666666666667\n",
      "1.0\n",
      "0.8990825688073394\n",
      "Accuracy metrics for label refugees:\n",
      "[[5083    0]\n",
      " [  39  114]]\n",
      "0.7450980392156863\n",
      "1.0\n",
      "0.8539325842696629\n",
      "Accuracy metrics for label death:\n",
      "[[5011    0]\n",
      " [  33  192]]\n",
      "0.8533333333333334\n",
      "1.0\n",
      "0.9208633093525179\n",
      "Accuracy metrics for label other_aid:\n",
      "[[4553    0]\n",
      " [ 160  523]]\n",
      "0.7657393850658858\n",
      "1.0\n",
      "0.867330016583748\n",
      "Accuracy metrics for label infrastructure_related:\n",
      "[[4904    0]\n",
      " [  69  263]]\n",
      "0.7921686746987951\n",
      "1.0\n",
      "0.8840336134453781\n",
      "Accuracy metrics for label transport:\n",
      "[[4994    0]\n",
      " [  46  196]]\n",
      "0.8099173553719008\n",
      "1.0\n",
      "0.8949771689497716\n",
      "Accuracy metrics for label buildings:\n",
      "[[4976    0]\n",
      " [  62  198]]\n",
      "0.7615384615384615\n",
      "1.0\n",
      "0.8646288209606987\n",
      "Accuracy metrics for label electricity:\n",
      "[[5125    0]\n",
      " [  25   86]]\n",
      "0.7747747747747747\n",
      "1.0\n",
      "0.8730964467005076\n",
      "Accuracy metrics for label tools:\n",
      "[[5202    0]\n",
      " [   8   26]]\n",
      "0.7647058823529411\n",
      "1.0\n",
      "0.8666666666666666\n",
      "Accuracy metrics for label hospitals:\n",
      "[[5187    0]\n",
      " [   8   41]]\n",
      "0.8367346938775511\n",
      "1.0\n",
      "0.9111111111111111\n",
      "Accuracy metrics for label shops:\n",
      "[[5208    0]\n",
      " [   6   22]]\n",
      "0.7857142857142857\n",
      "1.0\n",
      "0.88\n",
      "Accuracy metrics for label aid_centers:\n",
      "[[5187    0]\n",
      " [   3   46]]\n",
      "0.9387755102040817\n",
      "1.0\n",
      "0.968421052631579\n",
      "Accuracy metrics for label other_infrastructure:\n",
      "[[4999    0]\n",
      " [  59  178]]\n",
      "0.7510548523206751\n",
      "1.0\n",
      "0.8578313253012048\n",
      "Accuracy metrics for label weather_related:\n",
      "[[3767   22]\n",
      " [ 173 1274]]\n",
      "0.8804422944022114\n",
      "0.9830246913580247\n",
      "0.9289099526066351\n",
      "Accuracy metrics for label floods:\n",
      "[[4795    0]\n",
      " [  79  362]]\n",
      "0.8208616780045351\n",
      "1.0\n",
      "0.9016189290161893\n",
      "Accuracy metrics for label storm:\n",
      "[[4763    2]\n",
      " [  78  393]]\n",
      "0.8343949044585988\n",
      "0.9949367088607595\n",
      "0.907621247113164\n",
      "Accuracy metrics for label fire:\n",
      "[[5181    0]\n",
      " [  12   43]]\n",
      "0.7818181818181819\n",
      "1.0\n",
      "0.8775510204081634\n",
      "Accuracy metrics for label earthquake:\n",
      "[[4752    7]\n",
      " [  74  403]]\n",
      "0.8448637316561844\n",
      "0.9829268292682927\n",
      "0.9086809470124013\n",
      "Accuracy metrics for label cold:\n",
      "[[5129    0]\n",
      " [  25   82]]\n",
      "0.7663551401869159\n",
      "1.0\n",
      "0.8677248677248678\n",
      "Accuracy metrics for label other_weather:\n",
      "[[4966    2]\n",
      " [  66  202]]\n",
      "0.753731343283582\n",
      "0.9901960784313726\n",
      "0.8559322033898303\n",
      "Accuracy metrics for label direct_report:\n",
      "[[4185   14]\n",
      " [ 140  897]]\n",
      "0.8649951783992286\n",
      "0.9846322722283205\n",
      "0.9209445585215605\n",
      "\n",
      "Best Parameters: {'clf__estimator__max_features': 50, 'clf__estimator__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "conf_mat = evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5218,    0],\n",
       "       [   3,   15]], dtype=int64)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat['offer']['conf_mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5218,   15], dtype=int64)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(conf_mat['offer']['conf_mat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(conf_mat['offer']['conf_mat'], axis = 0)[np.sum(conf_mat['offer']['conf_mat'], axis = 0).shape[0] -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0713141  0.91201011 0.        ]\n",
      "[0.20990566 0.75318438 0.        ]\n",
      "[0.10645933 0.82502287        nan]\n",
      "[0.92193995 0.05518764]\n",
      "[0.82343234 0.12886598]\n",
      "[0.8699063  0.07727975]\n",
      "[1. 0.]\n",
      "[0.99656226        nan]\n",
      "[0.99827817        nan]\n",
      "[0.69628433 0.28958431]\n",
      "[0.58623504 0.3974359 ]\n",
      "[0.63653818 0.33504458]\n",
      "[0.99854681 0.        ]\n",
      "[0.91986996 0.        ]\n",
      "[0.95759506        nan]\n",
      "[0.9981895  0.00377358]\n",
      "[0.94948335 0.1       ]\n",
      "[0.97322742 0.00727273]\n",
      "[0.99980319 0.        ]\n",
      "[0.9703916 0.       ]\n",
      "[0.98487786        nan]\n",
      "[0.99961105 0.        ]\n",
      "[0.9820405 0.       ]\n",
      "[0.99074788        nan]\n",
      "[0.99980257 0.        ]\n",
      "[0.96733524 0.        ]\n",
      "[0.98330097        nan]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.99367347 0.00297619]\n",
      "[0.93562644 0.03125   ]\n",
      "[0.96377672 0.00543478]\n",
      "[0.96714623 0.03626943]\n",
      "[0.88976689 0.12068966]\n",
      "[0.92684433 0.05577689]\n",
      "[0.99455041 0.00860215]\n",
      "[0.91144833 0.13333333]\n",
      "[0.95118773 0.01616162]\n",
      "[0.99883653 0.        ]\n",
      "[0.98489484 0.        ]\n",
      "[0.99181669        nan]\n",
      "[0.99941257 0.        ]\n",
      "[0.97534875 0.        ]\n",
      "[0.98723404        nan]\n",
      "[1. 0.]\n",
      "[0.98854087        nan]\n",
      "[0.99423742        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\madke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n",
      "[0.97077922        nan]\n",
      "[0.98517298        nan]\n",
      "[0.99820395 0.        ]\n",
      "[0.95695428 0.        ]\n",
      "[0.97714397        nan]\n",
      "[0.99846255 0.00146413]\n",
      "[0.86954858 0.125     ]\n",
      "[0.9295573  0.00289436]\n",
      "[1. 0.]\n",
      "[0.93659282        nan]\n",
      "[0.96725838        nan]\n",
      "[0.99919904 0.        ]\n",
      "[0.95374618 0.        ]\n",
      "[0.97594367        nan]\n",
      "[0.99879421 0.00769231]\n",
      "[0.95065034 0.25      ]\n",
      "[0.97412779 0.01492537]\n",
      "[1. 0.]\n",
      "[0.97880061        nan]\n",
      "[0.98928675        nan]\n",
      "[0.99980777 0.        ]\n",
      "[0.99350525 0.        ]\n",
      "[0.99664655        nan]\n",
      "[1. 0.]\n",
      "[0.99064171        nan]\n",
      "[0.99529886        nan]\n",
      "[1. 0.]\n",
      "[0.99465241        nan]\n",
      "[0.99731903        nan]\n",
      "[1. 0.]\n",
      "[0.99064171        nan]\n",
      "[0.99529886        nan]\n",
      "[1.         0.00421941]\n",
      "[0.95491882 1.        ]\n",
      "[0.97693961 0.00840336]\n",
      "[0.85246767 0.13476158]\n",
      "[0.72066042 0.25862069]\n",
      "[0.7810422  0.17719219]\n",
      "[0.99395203 0.00453515]\n",
      "[0.91565802 0.06451613]\n",
      "[0.9532     0.00847458]\n",
      "[0.98656873 0.00636943]\n",
      "[0.90946024 0.04477612]\n",
      "[0.94644655 0.01115242]\n",
      "[1. 0.]\n",
      "[0.9894958       nan]\n",
      "[0.99472017        nan]\n",
      "[0.96217693 0.0293501 ]\n",
      "[0.90817136 0.07216495]\n",
      "[0.93439445 0.04172876]\n",
      "[1. 0.]\n",
      "[0.97956455        nan]\n",
      "[0.9896768       nan]\n",
      "[0.99919485 0.        ]\n",
      "[0.94877676 0.        ]\n",
      "[0.97333333        nan]\n",
      "[0.9206954  0.06750241]\n",
      "[0.79991724 0.17369727]\n",
      "[0.85606732 0.09722222]\n",
      "Confusion matrix for label related:\n",
      "[[  89 1151    8]\n",
      " [ 333 3607   15]\n",
      " [   2   31    0]]\n",
      "Confusion matrix for label request:\n",
      "[[3992  338]\n",
      " [ 856   50]]\n",
      "Confusion matrix for label offer:\n",
      "[[5218    0]\n",
      " [  18    0]]\n",
      "Confusion matrix for label aid_related:\n",
      "[[2155  940]\n",
      " [1521  620]]\n",
      "Confusion matrix for label medical_help:\n",
      "[[4810    7]\n",
      " [ 419    0]]\n",
      "Confusion matrix for label medical_products:\n",
      "[[4962    9]\n",
      " [ 264    1]]\n",
      "Confusion matrix for label search_and_rescue:\n",
      "[[5080    1]\n",
      " [ 155    0]]\n",
      "Confusion matrix for label security:\n",
      "[[5140    2]\n",
      " [  94    0]]\n",
      "Confusion matrix for label military:\n",
      "[[5064    1]\n",
      " [ 171    0]]\n",
      "Confusion matrix for label child_alone:\n",
      "[[5236]]\n",
      "Confusion matrix for label water:\n",
      "[[4869   31]\n",
      " [ 335    1]]\n",
      "Confusion matrix for label food:\n",
      "[[4504  153]\n",
      " [ 558   21]]\n",
      "Confusion matrix for label shelter:\n",
      "[[4745   26]\n",
      " [ 461    4]]\n",
      "Confusion matrix for label clothing:\n",
      "[[5151    6]\n",
      " [  79    0]]\n",
      "Confusion matrix for label money:\n",
      "[[5104    3]\n",
      " [ 129    0]]\n",
      "Confusion matrix for label missing_people:\n",
      "[[5176    0]\n",
      " [  60    0]]\n",
      "Confusion matrix for label refugees:\n",
      "[[5083    0]\n",
      " [ 153    0]]\n",
      "Confusion matrix for label death:\n",
      "[[5002    9]\n",
      " [ 225    0]]\n",
      "Confusion matrix for label other_aid:\n",
      "[[4546    7]\n",
      " [ 682    1]]\n",
      "Confusion matrix for label infrastructure_related:\n",
      "[[4904    0]\n",
      " [ 332    0]]\n",
      "Confusion matrix for label transport:\n",
      "[[4990    4]\n",
      " [ 242    0]]\n",
      "Confusion matrix for label buildings:\n",
      "[[4970    6]\n",
      " [ 258    2]]\n",
      "Confusion matrix for label electricity:\n",
      "[[5125    0]\n",
      " [ 111    0]]\n",
      "Confusion matrix for label tools:\n",
      "[[5201    1]\n",
      " [  34    0]]\n",
      "Confusion matrix for label hospitals:\n",
      "[[5187    0]\n",
      " [  49    0]]\n",
      "Confusion matrix for label shops:\n",
      "[[5208    0]\n",
      " [  28    0]]\n",
      "Confusion matrix for label aid_centers:\n",
      "[[5187    0]\n",
      " [  49    0]]\n",
      "Confusion matrix for label other_infrastructure:\n",
      "[[4999    0]\n",
      " [ 236    1]]\n",
      "Confusion matrix for label weather_related:\n",
      "[[3230  559]\n",
      " [1252  195]]\n",
      "Confusion matrix for label floods:\n",
      "[[4766   29]\n",
      " [ 439    2]]\n",
      "Confusion matrix for label storm:\n",
      "[[4701   64]\n",
      " [ 468    3]]\n",
      "Confusion matrix for label fire:\n",
      "[[5181    0]\n",
      " [  55    0]]\n",
      "Confusion matrix for label earthquake:\n",
      "[[4579  180]\n",
      " [ 463   14]]\n",
      "Confusion matrix for label cold:\n",
      "[[5129    0]\n",
      " [ 107    0]]\n",
      "Confusion matrix for label other_weather:\n",
      "[[4964    4]\n",
      " [ 268    0]]\n",
      "Confusion matrix for label direct_report:\n",
      "[[3866  333]\n",
      " [ 967   70]]\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(Y_test)\n",
    "y_pred = np.array(res)\n",
    "\n",
    "labels = category_names\n",
    "\n",
    "conf_mat_dict={}\n",
    "\n",
    "for label_col in range(len(labels)):\n",
    "    y_true_label = y_true[:, label_col]\n",
    "    y_pred_label = y_pred[:, label_col]\n",
    "    cm = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "    precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "    print(recall)\n",
    "    print(precision)\n",
    "    print (2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "\n",
    "\n",
    "for label, matrix in conf_mat_dict.items():\n",
    "    print(\"Confusion matrix for label {}:\".format(label))\n",
    "    print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
