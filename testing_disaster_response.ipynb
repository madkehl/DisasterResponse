{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"./models/train_classifier.py\").read())\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 21] The device is not ready: 'D:\\\\nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-30cb5300fffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/DisasterResponse.db\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(database_filepath)\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(txt)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mAP_MODEL_LOC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'file:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'taggers/averaged_perceptron_tagger/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[1;31m# Is the path item a zipfile?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.zip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X, Y, category_names = load_data(\"./data/DisasterResponse.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.222, total= 3.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.223, total= 4.1min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.234, total= 4.7min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.214, total= 4.9min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=2, score=0.227, total= 4.6min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.209, total= 2.4min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.202, total= 2.6min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.215, total= 2.9min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.205, total= 2.2min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=15, score=0.212, total= 2.2min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.203, total= 1.7min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.196, total= 1.8min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.205, total= 1.8min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.196, total= 1.8min\n",
      "[CV] clf__estimator__max_features=5, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=5, clf__estimator__min_samples_split=50, score=0.208, total= 1.6min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.225, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.222, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.239, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.215, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=2, score=0.234, total= 3.0min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.211, total= 1.7min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.209, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.217, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.206, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=15, score=0.213, total= 1.8min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.200, total= 1.4min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.197, total= 1.3min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.210, total= 1.3min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.196, total= 1.4min\n",
      "[CV] clf__estimator__max_features=10, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=10, clf__estimator__min_samples_split=50, score=0.207, total= 1.4min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.227, total= 2.7min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.230, total= 2.7min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.235, total= 2.6min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.218, total= 2.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=2 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=2, score=0.232, total= 3.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.215, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.213, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.223, total= 1.8min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.208, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=15 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=15, score=0.223, total= 1.5min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.214, total= 1.1min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.198, total= 1.2min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.217, total= 1.2min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.202, total= 1.1min\n",
      "[CV] clf__estimator__max_features=50, clf__estimator__min_samples_split=50 \n",
      "[CV]  clf__estimator__max_features=50, clf__estimator__min_samples_split=50, score=0.211, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 101.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf_vec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        st...\n",
       "                                                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                                                               n_estimators=100,\n",
       "                                                                                               n_jobs=None,\n",
       "                                                                                               oob_score=False,\n",
       "                                                                                               random_state=None,\n",
       "                                                                                               verbose=0,\n",
       "                                                                                               warm_start=False),\n",
       "                                                              n_jobs=-1))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__max_features': [5, 10, 50],\n",
       "                         'clf__estimator__min_samples_split': [2, 15, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res.columns = category_names\n",
    "#res2 = pd.melt(res, ignore_index=False)\n",
    "#res2 = res2[res2['value'] == 1]\n",
    "#res2 = res2.reset_index(drop = False).sort_values(by = 'index',axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1\n",
      "step2\n",
      "step3\n",
      "step4\n",
      "\n",
      "Best Parameters: {'clf__estimator__max_features': 50, 'clf__estimator__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "ps,rs,fs,ss  = evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93403376 0.5410628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.97748641 0.2786746  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.9552662  0.36787503 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[171985  16478     33      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "source": [
    "print(ps)\n",
    "print(rs)\n",
    "print(fs)\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = MultiLabelBinarizer().fit(Y_test)\n",
    "\n",
    "ps,rs,fs,ss  = precision_recall_fscore_support(np.array(Y_test).reshape(-1), np.array(res).reshape(-1), labels = range(0,36), average= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for label related:\n",
      "[[1048  199    1]\n",
      " [  20 3935    0]\n",
      " [   1    8   24]]\n",
      "Confusion matrix for label request:\n",
      "[[4322    8]\n",
      " [ 128  778]]\n",
      "Confusion matrix for label offer:\n",
      "[[5218    0]\n",
      " [   3   15]]\n",
      "Confusion matrix for label aid_related:\n",
      "[[3032   63]\n",
      " [ 195 1946]]\n",
      "Confusion matrix for label medical_help:\n",
      "[[4817    0]\n",
      " [  93  326]]\n",
      "Confusion matrix for label medical_products:\n",
      "[[4971    0]\n",
      " [  54  211]]\n",
      "Confusion matrix for label search_and_rescue:\n",
      "[[5081    0]\n",
      " [  26  129]]\n",
      "Confusion matrix for label security:\n",
      "[[5142    0]\n",
      " [  19   75]]\n",
      "Confusion matrix for label military:\n",
      "[[5065    0]\n",
      " [  31  140]]\n",
      "Confusion matrix for label child_alone:\n",
      "[[5236]]\n",
      "Confusion matrix for label water:\n",
      "[[4900    0]\n",
      " [  61  275]]\n",
      "Confusion matrix for label food:\n",
      "[[4652    5]\n",
      " [  91  488]]\n",
      "Confusion matrix for label shelter:\n",
      "[[4770    1]\n",
      " [  91  374]]\n",
      "Confusion matrix for label clothing:\n",
      "[[5157    0]\n",
      " [  15   64]]\n",
      "Confusion matrix for label money:\n",
      "[[5107    0]\n",
      " [  28  101]]\n",
      "Confusion matrix for label missing_people:\n",
      "[[5176    0]\n",
      " [  11   49]]\n",
      "Confusion matrix for label refugees:\n",
      "[[5083    0]\n",
      " [  39  114]]\n",
      "Confusion matrix for label death:\n",
      "[[5011    0]\n",
      " [  33  192]]\n",
      "Confusion matrix for label other_aid:\n",
      "[[4553    0]\n",
      " [ 160  523]]\n",
      "Confusion matrix for label infrastructure_related:\n",
      "[[4904    0]\n",
      " [  69  263]]\n",
      "Confusion matrix for label transport:\n",
      "[[4994    0]\n",
      " [  46  196]]\n",
      "Confusion matrix for label buildings:\n",
      "[[4976    0]\n",
      " [  62  198]]\n",
      "Confusion matrix for label electricity:\n",
      "[[5125    0]\n",
      " [  25   86]]\n",
      "Confusion matrix for label tools:\n",
      "[[5202    0]\n",
      " [   8   26]]\n",
      "Confusion matrix for label hospitals:\n",
      "[[5187    0]\n",
      " [   8   41]]\n",
      "Confusion matrix for label shops:\n",
      "[[5208    0]\n",
      " [   6   22]]\n",
      "Confusion matrix for label aid_centers:\n",
      "[[5187    0]\n",
      " [   3   46]]\n",
      "Confusion matrix for label other_infrastructure:\n",
      "[[4999    0]\n",
      " [  59  178]]\n",
      "Confusion matrix for label weather_related:\n",
      "[[3767   22]\n",
      " [ 173 1274]]\n",
      "Confusion matrix for label floods:\n",
      "[[4795    0]\n",
      " [  79  362]]\n",
      "Confusion matrix for label storm:\n",
      "[[4763    2]\n",
      " [  78  393]]\n",
      "Confusion matrix for label fire:\n",
      "[[5181    0]\n",
      " [  12   43]]\n",
      "Confusion matrix for label earthquake:\n",
      "[[4752    7]\n",
      " [  74  403]]\n",
      "Confusion matrix for label cold:\n",
      "[[5129    0]\n",
      " [  25   82]]\n",
      "Confusion matrix for label other_weather:\n",
      "[[4966    2]\n",
      " [  66  202]]\n",
      "Confusion matrix for label direct_report:\n",
      "[[4185   14]\n",
      " [ 140  897]]\n",
      "\n",
      "Best Parameters: {'clf__estimator__max_features': 50, 'clf__estimator__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "ps, rs, fs = evaluate_model(model, X_test, Y_test, category_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'related': array([0.90461804, 0.97196493, 0.82758621]),\n",
       " 'request': array([0.98451025, 0.91962175]),\n",
       " 'offer': array([0.99971262, 0.90909091]),\n",
       " 'aid_related': array([0.95919013, 0.93783133]),\n",
       " 'medical_help': array([0.99043898, 0.87516779]),\n",
       " 'medical_products': array([0.99459784, 0.88655462]),\n",
       " 'search_and_rescue': array([0.99744798, 0.9084507 ]),\n",
       " 'security': array([0.99815588, 0.88757396]),\n",
       " 'military': array([0.99694912, 0.90032154]),\n",
       " 'child_alone': array([1.]),\n",
       " 'water': array([0.99381401, 0.90016367]),\n",
       " 'food': array([0.98978723, 0.91044776]),\n",
       " 'shelter': array([0.9904485 , 0.89047619]),\n",
       " 'clothing': array([0.99854778, 0.8951049 ]),\n",
       " 'money': array([0.99726616, 0.87826087]),\n",
       " 'missing_people': array([0.99893853, 0.89908257]),\n",
       " 'refugees': array([0.99617834, 0.85393258]),\n",
       " 'death': array([0.99671805, 0.92086331]),\n",
       " 'other_aid': array([0.98273257, 0.86733002]),\n",
       " 'infrastructure_related': array([0.99301407, 0.88403361]),\n",
       " 'transport': array([0.99541559, 0.89497717]),\n",
       " 'buildings': array([0.99380867, 0.86462882]),\n",
       " 'electricity': array([0.99756691, 0.87309645]),\n",
       " 'tools': array([0.99923166, 0.86666667]),\n",
       " 'hospitals': array([0.99922944, 0.91111111]),\n",
       " 'shops': array([0.99942429, 0.88      ]),\n",
       " 'aid_centers': array([0.9997109 , 0.96842105]),\n",
       " 'other_infrastructure': array([0.99413344, 0.85783133]),\n",
       " 'weather_related': array([0.97477035, 0.92890995]),\n",
       " 'floods': array([0.99182956, 0.90161893]),\n",
       " 'storm': array([0.99167187, 0.90762125]),\n",
       " 'fire': array([0.99884326, 0.87755102]),\n",
       " 'earthquake': array([0.9915493 , 0.90868095]),\n",
       " 'cold': array([0.9975688 , 0.86772487]),\n",
       " 'other_weather': array([0.9932   , 0.8559322]),\n",
       " 'direct_report': array([0.98193336, 0.92094456])}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for label related:\n",
      "[[  89 1151    8]\n",
      " [ 333 3607   15]\n",
      " [   2   31    0]]\n",
      "Confusion matrix for label request:\n",
      "[[3992  338]\n",
      " [ 856   50]]\n",
      "Confusion matrix for label offer:\n",
      "[[5218    0]\n",
      " [  18    0]]\n",
      "Confusion matrix for label aid_related:\n",
      "[[2155  940]\n",
      " [1521  620]]\n",
      "Confusion matrix for label medical_help:\n",
      "[[4810    7]\n",
      " [ 419    0]]\n",
      "Confusion matrix for label medical_products:\n",
      "[[4962    9]\n",
      " [ 264    1]]\n",
      "Confusion matrix for label search_and_rescue:\n",
      "[[5080    1]\n",
      " [ 155    0]]\n",
      "Confusion matrix for label security:\n",
      "[[5140    2]\n",
      " [  94    0]]\n",
      "Confusion matrix for label military:\n",
      "[[5064    1]\n",
      " [ 171    0]]\n",
      "Confusion matrix for label child_alone:\n",
      "[[5236]]\n",
      "Confusion matrix for label water:\n",
      "[[4869   31]\n",
      " [ 335    1]]\n",
      "Confusion matrix for label food:\n",
      "[[4504  153]\n",
      " [ 558   21]]\n",
      "Confusion matrix for label shelter:\n",
      "[[4745   26]\n",
      " [ 461    4]]\n",
      "Confusion matrix for label clothing:\n",
      "[[5151    6]\n",
      " [  79    0]]\n",
      "Confusion matrix for label money:\n",
      "[[5104    3]\n",
      " [ 129    0]]\n",
      "Confusion matrix for label missing_people:\n",
      "[[5176    0]\n",
      " [  60    0]]\n",
      "Confusion matrix for label refugees:\n",
      "[[5083    0]\n",
      " [ 153    0]]\n",
      "Confusion matrix for label death:\n",
      "[[5002    9]\n",
      " [ 225    0]]\n",
      "Confusion matrix for label other_aid:\n",
      "[[4546    7]\n",
      " [ 682    1]]\n",
      "Confusion matrix for label infrastructure_related:\n",
      "[[4904    0]\n",
      " [ 332    0]]\n",
      "Confusion matrix for label transport:\n",
      "[[4990    4]\n",
      " [ 242    0]]\n",
      "Confusion matrix for label buildings:\n",
      "[[4970    6]\n",
      " [ 258    2]]\n",
      "Confusion matrix for label electricity:\n",
      "[[5125    0]\n",
      " [ 111    0]]\n",
      "Confusion matrix for label tools:\n",
      "[[5201    1]\n",
      " [  34    0]]\n",
      "Confusion matrix for label hospitals:\n",
      "[[5187    0]\n",
      " [  49    0]]\n",
      "Confusion matrix for label shops:\n",
      "[[5208    0]\n",
      " [  28    0]]\n",
      "Confusion matrix for label aid_centers:\n",
      "[[5187    0]\n",
      " [  49    0]]\n",
      "Confusion matrix for label other_infrastructure:\n",
      "[[4999    0]\n",
      " [ 236    1]]\n",
      "Confusion matrix for label weather_related:\n",
      "[[3230  559]\n",
      " [1252  195]]\n",
      "Confusion matrix for label floods:\n",
      "[[4766   29]\n",
      " [ 439    2]]\n",
      "Confusion matrix for label storm:\n",
      "[[4701   64]\n",
      " [ 468    3]]\n",
      "Confusion matrix for label fire:\n",
      "[[5181    0]\n",
      " [  55    0]]\n",
      "Confusion matrix for label earthquake:\n",
      "[[4579  180]\n",
      " [ 463   14]]\n",
      "Confusion matrix for label cold:\n",
      "[[5129    0]\n",
      " [ 107    0]]\n",
      "Confusion matrix for label other_weather:\n",
      "[[4964    4]\n",
      " [ 268    0]]\n",
      "Confusion matrix for label direct_report:\n",
      "[[3866  333]\n",
      " [ 967   70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "labels = Y_test\n",
    "predictions = res\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0713141  0.91201011 0.        ]\n",
      "[0.20990566 0.75318438 0.        ]\n",
      "[0.10645933 0.82502287        nan]\n",
      "[0.92193995 0.05518764]\n",
      "[0.82343234 0.12886598]\n",
      "[0.8699063  0.07727975]\n",
      "[1. 0.]\n",
      "[0.99656226        nan]\n",
      "[0.99827817        nan]\n",
      "[0.69628433 0.28958431]\n",
      "[0.58623504 0.3974359 ]\n",
      "[0.63653818 0.33504458]\n",
      "[0.99854681 0.        ]\n",
      "[0.91986996 0.        ]\n",
      "[0.95759506        nan]\n",
      "[0.9981895  0.00377358]\n",
      "[0.94948335 0.1       ]\n",
      "[0.97322742 0.00727273]\n",
      "[0.99980319 0.        ]\n",
      "[0.9703916 0.       ]\n",
      "[0.98487786        nan]\n",
      "[0.99961105 0.        ]\n",
      "[0.9820405 0.       ]\n",
      "[0.99074788        nan]\n",
      "[0.99980257 0.        ]\n",
      "[0.96733524 0.        ]\n",
      "[0.98330097        nan]\n",
      "[1.]\n",
      "[1.]\n",
      "[1.]\n",
      "[0.99367347 0.00297619]\n",
      "[0.93562644 0.03125   ]\n",
      "[0.96377672 0.00543478]\n",
      "[0.96714623 0.03626943]\n",
      "[0.88976689 0.12068966]\n",
      "[0.92684433 0.05577689]\n",
      "[0.99455041 0.00860215]\n",
      "[0.91144833 0.13333333]\n",
      "[0.95118773 0.01616162]\n",
      "[0.99883653 0.        ]\n",
      "[0.98489484 0.        ]\n",
      "[0.99181669        nan]\n",
      "[0.99941257 0.        ]\n",
      "[0.97534875 0.        ]\n",
      "[0.98723404        nan]\n",
      "[1. 0.]\n",
      "[0.98854087        nan]\n",
      "[0.99423742        nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\madke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\madke\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n",
      "[0.97077922        nan]\n",
      "[0.98517298        nan]\n",
      "[0.99820395 0.        ]\n",
      "[0.95695428 0.        ]\n",
      "[0.97714397        nan]\n",
      "[0.99846255 0.00146413]\n",
      "[0.86954858 0.125     ]\n",
      "[0.9295573  0.00289436]\n",
      "[1. 0.]\n",
      "[0.93659282        nan]\n",
      "[0.96725838        nan]\n",
      "[0.99919904 0.        ]\n",
      "[0.95374618 0.        ]\n",
      "[0.97594367        nan]\n",
      "[0.99879421 0.00769231]\n",
      "[0.95065034 0.25      ]\n",
      "[0.97412779 0.01492537]\n",
      "[1. 0.]\n",
      "[0.97880061        nan]\n",
      "[0.98928675        nan]\n",
      "[0.99980777 0.        ]\n",
      "[0.99350525 0.        ]\n",
      "[0.99664655        nan]\n",
      "[1. 0.]\n",
      "[0.99064171        nan]\n",
      "[0.99529886        nan]\n",
      "[1. 0.]\n",
      "[0.99465241        nan]\n",
      "[0.99731903        nan]\n",
      "[1. 0.]\n",
      "[0.99064171        nan]\n",
      "[0.99529886        nan]\n",
      "[1.         0.00421941]\n",
      "[0.95491882 1.        ]\n",
      "[0.97693961 0.00840336]\n",
      "[0.85246767 0.13476158]\n",
      "[0.72066042 0.25862069]\n",
      "[0.7810422  0.17719219]\n",
      "[0.99395203 0.00453515]\n",
      "[0.91565802 0.06451613]\n",
      "[0.9532     0.00847458]\n",
      "[0.98656873 0.00636943]\n",
      "[0.90946024 0.04477612]\n",
      "[0.94644655 0.01115242]\n",
      "[1. 0.]\n",
      "[0.9894958       nan]\n",
      "[0.99472017        nan]\n",
      "[0.96217693 0.0293501 ]\n",
      "[0.90817136 0.07216495]\n",
      "[0.93439445 0.04172876]\n",
      "[1. 0.]\n",
      "[0.97956455        nan]\n",
      "[0.9896768       nan]\n",
      "[0.99919485 0.        ]\n",
      "[0.94877676 0.        ]\n",
      "[0.97333333        nan]\n",
      "[0.9206954  0.06750241]\n",
      "[0.79991724 0.17369727]\n",
      "[0.85606732 0.09722222]\n",
      "Confusion matrix for label related:\n",
      "[[  89 1151    8]\n",
      " [ 333 3607   15]\n",
      " [   2   31    0]]\n",
      "Confusion matrix for label request:\n",
      "[[3992  338]\n",
      " [ 856   50]]\n",
      "Confusion matrix for label offer:\n",
      "[[5218    0]\n",
      " [  18    0]]\n",
      "Confusion matrix for label aid_related:\n",
      "[[2155  940]\n",
      " [1521  620]]\n",
      "Confusion matrix for label medical_help:\n",
      "[[4810    7]\n",
      " [ 419    0]]\n",
      "Confusion matrix for label medical_products:\n",
      "[[4962    9]\n",
      " [ 264    1]]\n",
      "Confusion matrix for label search_and_rescue:\n",
      "[[5080    1]\n",
      " [ 155    0]]\n",
      "Confusion matrix for label security:\n",
      "[[5140    2]\n",
      " [  94    0]]\n",
      "Confusion matrix for label military:\n",
      "[[5064    1]\n",
      " [ 171    0]]\n",
      "Confusion matrix for label child_alone:\n",
      "[[5236]]\n",
      "Confusion matrix for label water:\n",
      "[[4869   31]\n",
      " [ 335    1]]\n",
      "Confusion matrix for label food:\n",
      "[[4504  153]\n",
      " [ 558   21]]\n",
      "Confusion matrix for label shelter:\n",
      "[[4745   26]\n",
      " [ 461    4]]\n",
      "Confusion matrix for label clothing:\n",
      "[[5151    6]\n",
      " [  79    0]]\n",
      "Confusion matrix for label money:\n",
      "[[5104    3]\n",
      " [ 129    0]]\n",
      "Confusion matrix for label missing_people:\n",
      "[[5176    0]\n",
      " [  60    0]]\n",
      "Confusion matrix for label refugees:\n",
      "[[5083    0]\n",
      " [ 153    0]]\n",
      "Confusion matrix for label death:\n",
      "[[5002    9]\n",
      " [ 225    0]]\n",
      "Confusion matrix for label other_aid:\n",
      "[[4546    7]\n",
      " [ 682    1]]\n",
      "Confusion matrix for label infrastructure_related:\n",
      "[[4904    0]\n",
      " [ 332    0]]\n",
      "Confusion matrix for label transport:\n",
      "[[4990    4]\n",
      " [ 242    0]]\n",
      "Confusion matrix for label buildings:\n",
      "[[4970    6]\n",
      " [ 258    2]]\n",
      "Confusion matrix for label electricity:\n",
      "[[5125    0]\n",
      " [ 111    0]]\n",
      "Confusion matrix for label tools:\n",
      "[[5201    1]\n",
      " [  34    0]]\n",
      "Confusion matrix for label hospitals:\n",
      "[[5187    0]\n",
      " [  49    0]]\n",
      "Confusion matrix for label shops:\n",
      "[[5208    0]\n",
      " [  28    0]]\n",
      "Confusion matrix for label aid_centers:\n",
      "[[5187    0]\n",
      " [  49    0]]\n",
      "Confusion matrix for label other_infrastructure:\n",
      "[[4999    0]\n",
      " [ 236    1]]\n",
      "Confusion matrix for label weather_related:\n",
      "[[3230  559]\n",
      " [1252  195]]\n",
      "Confusion matrix for label floods:\n",
      "[[4766   29]\n",
      " [ 439    2]]\n",
      "Confusion matrix for label storm:\n",
      "[[4701   64]\n",
      " [ 468    3]]\n",
      "Confusion matrix for label fire:\n",
      "[[5181    0]\n",
      " [  55    0]]\n",
      "Confusion matrix for label earthquake:\n",
      "[[4579  180]\n",
      " [ 463   14]]\n",
      "Confusion matrix for label cold:\n",
      "[[5129    0]\n",
      " [ 107    0]]\n",
      "Confusion matrix for label other_weather:\n",
      "[[4964    4]\n",
      " [ 268    0]]\n",
      "Confusion matrix for label direct_report:\n",
      "[[3866  333]\n",
      " [ 967   70]]\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(Y_test)\n",
    "y_pred = np.array(res)\n",
    "\n",
    "labels = category_names\n",
    "\n",
    "conf_mat_dict={}\n",
    "\n",
    "for label_col in range(len(labels)):\n",
    "    y_true_label = y_true[:, label_col]\n",
    "    y_pred_label = y_pred[:, label_col]\n",
    "    cm = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "    precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "    print(recall)\n",
    "    print(precision)\n",
    "    print (2 * (precision * recall) / (precision + recall))\n",
    "\n",
    "\n",
    "\n",
    "for label, matrix in conf_mat_dict.items():\n",
    "    print(\"Confusion matrix for label {}:\".format(label))\n",
    "    print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
